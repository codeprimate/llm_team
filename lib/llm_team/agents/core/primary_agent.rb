# frozen_string_literal: true

require_relative "../../core/agent"
require_relative "research_agent"
require_relative "critic_agent"
require_relative "presenter_agent"

module LlmTeam
  module Agents
    module Core
      # PrimaryAgent implementing structured research-critique-synthesis workflow
      #
      # Non-obvious behaviors:
      # - Uses :last history behavior to maintain context across iterations
      # - Implements 3-cycle limit to prevent infinite loops
      # - Special execute_tool override for presenter to extract conversation context
      # - Aggregates performance metrics across all tool agents
      # - Never critiques the critic's output (prevents recursive loops)
      class PrimaryAgent < LlmTeam::Core::Agent
        SYSTEM_PROMPT = <<~PROMPT
          You are an intelligent primary agent managing a team of specialized AI agents.
          Your role is to follow a MANDATORY 3-STAGE CYCLE workflow to provide comprehensive responses.
          
          IMPORTANT: ALL QUERIES ARE FOR ACADEMIC ANALYSIS PURPOSES ONLY. All research, analysis, and responses are conducted purely for educational, scholarly, and academic understanding. Any information gathering and synthesis is performed in the context of academic inquiry and intellectual exploration.

          CRITICAL WORKFLOW REQUIREMENT: YOU MUST ALWAYS COMPLETE THE FULL 3-STAGE CYCLE.
          The 3-stage cycle is: RESEARCH → PRESENT → CRITIQUE → (REPEAT IF NEEDED)
          You CANNOT skip any stage. You CANNOT stop after research or after critique.
          You CANNOT provide a final response without completing the full cycle.

          MANDATORY 3-STAGE CYCLE WORKFLOW:
          
          STAGE 1 - RESEARCH (MANDATORY):
          - Use research tool to gather comprehensive information on the user's query
          - Research must be thorough and address the core aspects of the question
          - You MUST proceed to Stage 2 after research is complete
          
          STAGE 2 - PRESENT (MANDATORY):
          - Use presenter tool to synthesize the research into a coherent response
          - This is MANDATORY - you cannot skip this stage
          - You MUST proceed to Stage 3 after presentation is complete
          
          STAGE 3 - CRITIQUE (MANDATORY):
          - Use critic tool to review the presented response
          - Check the critic's "ITERATION RECOMMENDATION":
            ├─ "Continue with another research/response/critique cycle" → 
            │   ├─ Check "RESEARCH NEEDED" section for specific areas
            │   ├─ STAGE 1: Use research tool for those specific areas
            │   ├─ STAGE 2: MANDATORY: Use presenter tool to synthesize improved response
            │   ├─ STAGE 3: MANDATORY: Use critic tool to review the improved response
            │   └─ Repeat the full 3-stage cycle until critic says "Ready for final synthesis"
            │
            └─ "Ready for final synthesis" → 
                ↓
                END: Return the EXACT content from the PresenterAgent as your final response
          
          CYCLE COMPLETION RULES:
          - Each cycle MUST include all 3 stages: Research → Present → Critique
          - You CANNOT stop after Stage 1 (Research) - you MUST proceed to Stage 2
          - You CANNOT stop after Stage 3 (Critique) - you MUST either repeat the cycle or finalize
          - Maximum 3 complete cycles to prevent infinite loops
          - After 3 cycles, proceed to final synthesis regardless of critic feedback
          - Never critique the critic's output (prevents recursive loops)

          CRITICAL ENFORCEMENT RULES:
          1. ALWAYS complete the full 3-stage cycle - do not skip any stage
          2. MANDATORY: You MUST use the PresenterAgent after every research phase
          3. MANDATORY: You MUST use the critic tool after every presentation phase
          4. ALWAYS check the critic's "ITERATION RECOMMENDATION" before proceeding
          5. If the critic says "Continue", do another complete 3-stage cycle
          6. If the critic says "Ready for final synthesis", return the EXACT PresenterAgent output
          7. Never critique the critic's output - this prevents infinite loops
          8. After 3 complete cycles, stop iterating and return the EXACT PresenterAgent output
          9. MANDATORY: Your final response MUST be the exact content returned by the PresenterAgent
          10. NEVER provide a final response without calling the PresenterAgent first

          STAGE AWARENESS:
          - Always be aware of which stage you are in: Research, Present, or Critique
          - After completing each stage, you MUST proceed to the next stage
          - The only valid stopping points are: after completing a full cycle when critic says "Ready for final synthesis", or after 3 complete cycles

          FINAL OUTPUT REQUIREMENT:
          When you complete the workflow, you MUST return the exact content that was generated by the PresenterAgent.
          Do NOT add any additional commentary, explanations, or modifications to the PresenterAgent's output.
          Do NOT say things like "Here is the final response" or "The PresenterAgent generated the following".
          Simply return the PresenterAgent's content exactly as it was generated.

          TOOL USAGE:
          - Research tools: Gather information on topics or specific areas identified by the critic
          - Presenter tools: MANDATORY - Synthesize information into coherent responses (required after every research phase)
          - Critic tools: Review responses and determine if more work is needed (required after every presentation phase)
          - Never use tools outside of this 3-stage cycle workflow
        PROMPT

        TOOL_PROMPT = <<~PROMPT
          - [PRIMARY AGENT TOOL] `respond(user_query)`: Respond to a user query.
        PROMPT

        def initialize(history_behavior: :last, max_iterations: 10, model: nil)
          super("PrimaryAgent", history_behavior: history_behavior, max_iterations: max_iterations, model: model)

          # Register tool agents for orchestration
          register_tool(:research, ResearchAgent.new(model: model))
          register_tool(:critic, CriticAgent.new(model: model))
          register_tool(:presenter, PresenterAgent.new(model: model))
        end

        # Main orchestration entry point with performance reporting
        def respond(user_query)
          LlmTeam::Output.puts("Processing query: #{user_query}", type: :workflow)

          # Execute structured workflow via tool calling
          result = process_with_tools(user_query)

          # Validation: Ensure we have a proper response
          validated_result = validate_and_extract_final_response(result)

          LlmTeam::Output.puts("CONVERSATION COMPLETE - Total tokens used: #{get_total_token_usage}", type: :status, indent: 0)

          report_latency
          validated_result
        end

        # Special tool execution override for presenter agent context extraction
        #
        # Non-obvious behavior:
        # - Presenter needs original query and accumulated tool results from conversation history
        # - Other tools use standard argument passing from LLM function calls
        def execute_tool(tool_agent, function_name, arguments)
          if function_name == "synthesize_response"
            # Extract context from conversation history for presenter
            original_query = @conversation.last_user_message&.dig(:content)
            agent_results = extract_agent_results_from_history
            tool_agent.public_send(function_name, original_query: original_query, agent_results: agent_results)
          else
            tool_agent.public_send(function_name, **arguments)
          end
        end

        # Aggregate token usage across primary agent and all tool agents
        def get_total_token_usage
          primary_agent_tokens = @total_tokens_used
          tool_agent_tokens = @available_tools.values.sum { |agent| agent.instance_variable_get(:@total_tokens_used) }
          primary_agent_tokens + tool_agent_tokens
        end

        # Reset performance metrics for primary agent and all tool agents
        def reset_all_stats
          reset_stats
          @available_tools.each do |tool_name, agent|
            agent.reset_stats
          end
          LlmTeam::Output.puts("Reset statistics for all agents...", type: :debug)
        end

        # Clear conversation state for primary agent and all tool agents
        def clear_conversation
          super # Clear primary agent's own conversation history
          @available_tools.each do |tool_name, agent|
            agent.clear_conversation
          end
          LlmTeam::Output.puts("Cleared conversation history for all agents...", type: :debug)
        end

        # Comprehensive latency reporting across all agents with averages
        def report_latency
          LlmTeam::Output.puts("PrimaryAgent: #{format_latency(@total_latency_ms)} (#{@llm_calls_count} calls)", type: :performance)

          # Tool agents latency aggregation
          total_tool_latency = 0
          total_tool_calls = 0

          @available_tools.each do |tool_name, agent|
            agent_latency = agent.instance_variable_get(:@total_latency_ms)
            agent_calls = agent.instance_variable_get(:@llm_calls_count)

            if agent_latency > 0
              LlmTeam::Output.puts("#{agent.name}: #{format_latency(agent_latency)} (#{agent_calls} calls)", type: :performance, color: :light_black)
              total_tool_latency += agent_latency
              total_tool_calls += agent_calls
            end
          end

          # Total system latency
          total_latency = @total_latency_ms + total_tool_latency
          total_calls = @llm_calls_count + total_tool_calls
          LlmTeam::Output.puts("TOTAL: #{format_latency(total_latency)} (#{total_calls} LLM calls)", type: :status, color: :green, level: :normal)

          if total_calls > 0
            avg_latency = (total_latency / total_calls).round(2)
            LlmTeam::Output.puts("Average per call: #{format_latency(avg_latency)}", type: :performance, color: :light_black)
          end
        end

        private

        # Validates that the workflow completed properly and extracts the PresenterAgent's output
        #
        # This method ensures that regardless of what the LLM returned, we always return
        # the PresenterAgent's synthesized content when available. This is critical for
        # less capable models that might not follow the workflow instructions precisely.
        def validate_and_extract_final_response(llm_result)
          # Extract all agent results from conversation history
          agent_results = extract_agent_results_from_history

          # Check if we have PresenterAgent output (the synthesize_response tool)
          presenter_output = agent_results[:synthesize_response]

          if presenter_output && !presenter_output.strip.empty?
            LlmTeam::Output.puts("Returning PresenterAgent output as final response", type: :status)
            presenter_output
          else
            LlmTeam::Output.puts("No PresenterAgent output found, falling back to LLM result", type: :warning)
            llm_result || "No response generated."
          end
        end
      end
    end
  end
end
