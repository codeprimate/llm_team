# frozen_string_literal: true

require_relative "../../core/agent"
require_relative "research_agent"
require_relative "critic_agent"
require_relative "presenter_agent"

module LlmTeam
  module Agents
    module Core
      # PrimaryAgent implementing structured research-critique-synthesis workflow
      #
      # Non-obvious behaviors:
      # - Uses :last history behavior to maintain context across iterations
      # - Implements 3-cycle limit to prevent infinite loops
      # - Special execute_tool override for presenter to extract conversation context
      # - Aggregates performance metrics across all tool agents
      # - Never critiques the critic's output (prevents recursive loops)
      class PrimaryAgent < LlmTeam::Core::Agent
        SYSTEM_PROMPT = <<~PROMPT
          You are an intelligent primary agent managing a team of specialized AI agents.
          Your role is to follow a systematic decision tree workflow to provide comprehensive responses.

          DECISION TREE WORKFLOW:
          Follow this exact decision tree to determine your next action:
          
          START: User asks a question
          ‚Üì
          Use research tool to gather initial information
          ‚Üì
          Use presenter tool to synthesize a comprehensive response from available information
          ‚Üì
          ALWAYS: Use critic tool to review the synthesized response
          ‚Üì
          Check the critic's "ITERATION RECOMMENDATION":
          ‚îú‚îÄ "Continue with another research/response/critique cycle" ‚Üí 
          ‚îÇ   ‚îú‚îÄ Check "RESEARCH NEEDED" section for specific areas
          ‚îÇ   ‚îú‚îÄ Use research tool for those specific areas
          ‚îÇ   ‚îú‚îÄ Use presenter tool to synthesize improved response
          ‚îÇ   ‚îú‚îÄ ALWAYS: Use critic tool to review the improved response
          ‚îÇ   ‚îî‚îÄ Repeat until critic says "Ready for final synthesis"
          ‚îÇ
          ‚îî‚îÄ "Ready for final synthesis" ‚Üí 
              ‚Üì
              END: Return the EXACT content from the PresenterAgent as your final response
          
          TERMINATION SAFEGUARDS:
          - Maximum 3 research/critique cycles to prevent infinite loops
          - If you reach 3 cycles, proceed to final synthesis regardless
          - Never critique the critic's output (prevents recursive loops)

          CRITICAL RULES:
          1. ALWAYS follow the decision tree exactly - do not skip steps
          2. ALWAYS use the critic tool after every synthesis
          3. ALWAYS check the critic's "ITERATION RECOMMENDATION" before proceeding
          4. If the critic says "Continue", do more research on the specific areas it identifies
          5. If the critic says "Ready for final synthesis", return the EXACT PresenterAgent output as your final response
          6. Never critique the critic's output - this prevents infinite loops
          7. After 3 complete cycles, stop iterating and return the EXACT PresenterAgent output as your final response
          8. MANDATORY: Your final response MUST be the exact content returned by the PresenterAgent - no modifications, no additions, no omissions

          FINAL OUTPUT REQUIREMENT:
          When you complete the workflow, you MUST return the exact content that was generated by the PresenterAgent.
          Do NOT add any additional commentary, explanations, or modifications to the PresenterAgent's output.
          Do NOT say things like "Here is the final response" or "The PresenterAgent generated the following".
          Simply return the PresenterAgent's content exactly as it was generated.

          TOOL USAGE:
          - Research tools: Gather information on topics or specific areas identified by the critic
          - Presenter tools: Synthesize information into coherent responses
          - Critic tools: Review responses and determine if more work is needed
          - Never use tools outside of this decision tree workflow
        PROMPT

        TOOL_PROMPT = <<~PROMPT
          - [PRIMARY AGENT TOOL] `respond(user_query)`: Respond to a user query.
        PROMPT

        def initialize(history_behavior: :last, max_iterations: 10, model: nil)
          super("PrimaryAgent", history_behavior: history_behavior, max_iterations: max_iterations, model: model)

          # Register tool agents for orchestration
          register_tool(:research, ResearchAgent.new(model: model))
          register_tool(:critic, CriticAgent.new(model: model))
          register_tool(:presenter, PresenterAgent.new(model: model))
        end

        # Main orchestration entry point with performance reporting
        def respond(user_query)
          puts "\nüéØ Processing query: #{user_query}".blue.bold

          # Execute structured workflow via tool calling
          result = process_with_tools(user_query)

          # Validation: Ensure we have a proper response
          validated_result = validate_and_extract_final_response(result)

          puts "\nüéØ CONVERSATION COMPLETE - Total tokens used: #{get_total_token_usage}".green.bold

          report_latency
          validated_result
        end

        # Special tool execution override for presenter agent context extraction
        #
        # Non-obvious behavior:
        # - Presenter needs original query and accumulated tool results from conversation history
        # - Other tools use standard argument passing from LLM function calls
        def execute_tool(tool_agent, function_name, arguments)
          if function_name == "synthesize_response"
            # Extract context from conversation history for presenter
            original_query = @conversation.last_user_message&.dig(:content)
            agent_results = extract_agent_results_from_history
            tool_agent.public_send(function_name, original_query: original_query, agent_results: agent_results)
          else
            tool_agent.public_send(function_name, **arguments)
          end
        end

        # Aggregate token usage across primary agent and all tool agents
        def get_total_token_usage
          primary_agent_tokens = @total_tokens_used
          tool_agent_tokens = @available_tools.values.sum { |agent| agent.instance_variable_get(:@total_tokens_used) }
          primary_agent_tokens + tool_agent_tokens
        end

        # Reset performance metrics for primary agent and all tool agents
        def reset_all_stats
          reset_stats
          @available_tools.each do |tool_name, agent|
            agent.reset_stats
          end
          puts "\nüßπ Reset statistics for all agents...".blue.bold
        end

        # Clear conversation state for primary agent and all tool agents
        def clear_conversation
          super # Clear primary agent's own conversation history
          @available_tools.each do |tool_name, agent|
            agent.clear_conversation
          end
          puts "\nüßπ Cleared conversation history for all agents...".blue.bold
        end

        # Comprehensive latency reporting across all agents with averages
        def report_latency
          puts "\nüìä LATENCY REPORT".blue.bold
          puts "‚îÄ" * 30

          # PrimaryAgent latency
          puts "üéØ PrimaryAgent: #{format_latency(@total_latency_ms)} (#{@llm_calls_count} calls)".cyan

          # Tool agents latency aggregation
          total_tool_latency = 0
          total_tool_calls = 0

          @available_tools.each do |tool_name, agent|
            agent_latency = agent.instance_variable_get(:@total_latency_ms)
            agent_calls = agent.instance_variable_get(:@llm_calls_count)

            if agent_latency > 0
              puts "üîß #{agent.name}: #{format_latency(agent_latency)} (#{agent_calls} calls)".light_black
              total_tool_latency += agent_latency
              total_tool_calls += agent_calls
            end
          end

          # Total system latency
          total_latency = @total_latency_ms + total_tool_latency
          total_calls = @llm_calls_count + total_tool_calls

          puts "‚îÄ" * 30
          puts "üìà TOTAL: #{format_latency(total_latency)} (#{total_calls} LLM calls)".green.bold

          if total_calls > 0
            avg_latency = (total_latency / total_calls).round(2)
            puts "üìä Average per call: #{format_latency(avg_latency)}".light_black
          end

          puts "‚îÄ" * 30
        end

        private

        # Validates that the workflow completed properly and extracts the PresenterAgent's output
        #
        # This method ensures that regardless of what the LLM returned, we always return
        # the PresenterAgent's synthesized content when available. This is critical for
        # less capable models that might not follow the workflow instructions precisely.
        def validate_and_extract_final_response(llm_result)
          # Extract all agent results from conversation history
          agent_results = extract_agent_results_from_history

          # Check if we have PresenterAgent output (the synthesize_response tool)
          presenter_output = agent_results[:synthesize_response]

          if presenter_output && !presenter_output.strip.empty?
            puts "\n‚úÖ Returning PresenterAgent output as final response".green.bold
            presenter_output
          else
            puts "\n‚ö†Ô∏è  No PresenterAgent output found, falling back to LLM result".yellow
            llm_result || "No response generated."
          end
        end
      end
    end
  end
end
